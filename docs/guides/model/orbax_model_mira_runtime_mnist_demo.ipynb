{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQTEH0FHaxOw"
      },
      "source": [
        "# Demo Notebook\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FogfMzupwKSe"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import jax\n",
        "import absl.flags as flags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Vb9xgbr5_6wV"
      },
      "outputs": [],
      "source": [
        "# This needs to be run first before any JAX code, to force JAX to use CPU in our demo for training.\n",
        "num_cpu_devices = 4\n",
        "xla_flags = os.getenv('XLA_FLAGS', '')\n",
        "xla_flags = re.sub(\n",
        "    r'--xla_force_host_platform_device_count=\\S+', '', xla_flags\n",
        ").split()\n",
        "os.environ['XLA_FLAGS'] = ' '.join(\n",
        "    [f'--xla_force_host_platform_device_count={num_cpu_devices}'] + xla_flags\n",
        ")\n",
        "jax.config.update('jax_platforms', 'cpu')\n",
        "flags.FLAGS.jax_allow_unused_tpus = True\n",
        "jax.devices()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dT22moqlePJx"
      },
      "source": [
        "## Create and Train Mnist Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kH3gUQ8gBh8_"
      },
      "outputs": [],
      "source": [
        "from flax import linen as nn\n",
        "from flax.training import train_state\n",
        "import jax.numpy as jnp\n",
        "import ml_collections\n",
        "import numpy as np\n",
        "import optax\n",
        "import tensorflow_datasets as tfds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "pgeG-L1pefHt"
      },
      "outputs": [],
      "source": [
        "# Load the MNIST train and test datasets into memory.\n",
        "def get_datasets():\n",
        "\n",
        "  ds_builder = tfds.builder('mnist')\n",
        "  ds_builder.download_and_prepare()\n",
        "  train_ds = tfds.as_numpy(ds_builder.as_dataset(split='train', batch_size=-1))\n",
        "  test_ds = tfds.as_numpy(ds_builder.as_dataset(split='test', batch_size=-1))\n",
        "  train_ds['image'] = jnp.float32(train_ds['image']) / 255.0\n",
        "  test_ds['image'] = jnp.float32(test_ds['image']) / 255.0\n",
        "  return train_ds, test_ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "b3S0XY0aBoit"
      },
      "outputs": [],
      "source": [
        "# Define the model.\n",
        "\n",
        "class Mnist(nn.Module):\n",
        "  \"\"\"A simple CNN model.\"\"\"\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, x):\n",
        "    x = nn.Conv(features=32, kernel_size=(3, 3))(x)\n",
        "    x = nn.relu(x)\n",
        "    x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
        "    x = nn.Conv(features=64, kernel_size=(3, 3))(x)\n",
        "    x = nn.relu(x)\n",
        "    x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
        "    x = x.reshape((x.shape[0], -1))  # flatten\n",
        "    x = nn.Dense(features=256)(x)\n",
        "    x = nn.relu(x)\n",
        "    x = nn.Dense(features=10)(x)\n",
        "    return x\n",
        "\n",
        "# Define train step.\n",
        "\n",
        "@jax.jit\n",
        "def apply_model(state, images, labels):\n",
        "  \"\"\"Computes gradients, loss and accuracy for a single batch.\"\"\"\n",
        "\n",
        "  def loss_fn(params):\n",
        "    logits = state.apply_fn({'params': params}, images)\n",
        "    one_hot = jax.nn.one_hot(labels, 10)\n",
        "    loss = jnp.mean(optax.softmax_cross_entropy(logits=logits, labels=one_hot))\n",
        "    return loss, logits\n",
        "\n",
        "  grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
        "  (loss, logits), grads = grad_fn(state.params)\n",
        "  accuracy = jnp.mean(jnp.argmax(logits, -1) == labels)\n",
        "  return grads, loss, accuracy\n",
        "\n",
        "\n",
        "@jax.jit\n",
        "def update_model(state, grads):\n",
        "  return state.apply_gradients(grads=grads)\n",
        "\n",
        "# Create train state.\n",
        "\n",
        "def create_train_state(rng, config):\n",
        "  \"\"\"Creates initial `TrainState`.\"\"\"\n",
        "  mnist = Mnist()\n",
        "  params = mnist.init(rng, jnp.ones([1, 28, 28, 1]))['params']\n",
        "  tx = optax.sgd(config.learning_rate, config.momentum)\n",
        "  return train_state.TrainState.create(apply_fn=mnist.apply, params=params, tx=tx)\n",
        "\n",
        "# Define train loop.\n",
        "\n",
        "def train_epoch(state, train_ds, batch_size, rng):\n",
        "  \"\"\"Train for a single epoch.\"\"\"\n",
        "  train_ds_size = len(train_ds['image'])\n",
        "  steps_per_epoch = train_ds_size // batch_size\n",
        "\n",
        "  perms = jax.random.permutation(rng, len(train_ds['image']))\n",
        "  perms = perms[: steps_per_epoch * batch_size]  # skip incomplete batch\n",
        "  perms = perms.reshape((steps_per_epoch, batch_size))\n",
        "\n",
        "  epoch_loss = []\n",
        "  epoch_accuracy = []\n",
        "\n",
        "  for perm in perms:\n",
        "    batch_images = train_ds['image'][perm, ...]\n",
        "    batch_labels = train_ds['label'][perm, ...]\n",
        "    grads, loss, accuracy = apply_model(state, batch_images, batch_labels)\n",
        "    state = update_model(state, grads)\n",
        "    epoch_loss.append(loss)\n",
        "    epoch_accuracy.append(accuracy)\n",
        "  train_loss = np.mean(epoch_loss)\n",
        "  train_accuracy = np.mean(epoch_accuracy)\n",
        "  return state, train_loss, train_accuracy\n",
        "\n",
        "# Define model training and evaluation loop.\n",
        "def train_and_evaluate(\n",
        "    config: ml_collections.ConfigDict\n",
        ") -> train_state.TrainState:\n",
        "  \"\"\"Execute model training and evaluation loop.\n",
        "\n",
        "  Args:\n",
        "    config: Hyperparameter configuration for training and evaluation.\n",
        "\n",
        "  Returns:\n",
        "    The train state (which includes the `.params`).\n",
        "  \"\"\"\n",
        "  train_ds, test_ds = get_datasets()\n",
        "  rng = jax.random.key(0)\n",
        "\n",
        "  rng, init_rng = jax.random.split(rng)\n",
        "  state = create_train_state(init_rng, config)\n",
        "\n",
        "  for epoch in range(1, config.num_epochs + 1):\n",
        "    rng, input_rng = jax.random.split(rng)\n",
        "    state, train_loss, train_accuracy = train_epoch(\n",
        "        state, train_ds, config.batch_size, input_rng\n",
        "    )\n",
        "    # Evaluate model on test set.\n",
        "    _, test_loss, test_accuracy = apply_model(\n",
        "        state, test_ds['image'], test_ds['label']\n",
        "    )\n",
        "\n",
        "    print(\n",
        "        'epoch:% 3d, train_loss: %.4f, train_accuracy: %.2f, test_loss: %.4f,'\n",
        "        ' test_accuracy: %.2f'\n",
        "        % (\n",
        "            epoch,\n",
        "            train_loss,\n",
        "            train_accuracy * 100,\n",
        "            test_loss,\n",
        "            test_accuracy * 100,\n",
        "        )\n",
        "    )\n",
        "  # Return the train state (including the params/weights)\n",
        "  return state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Nh15w62yEaIY"
      },
      "outputs": [],
      "source": [
        "# Create the configuration of hyperparameters, feel free to tune them.\n",
        "def get_config():\n",
        "  config = ml_collections.ConfigDict()\n",
        "  config.learning_rate = 0.1\n",
        "  config.momentum = 0.9\n",
        "  config.batch_size = 128\n",
        "  config.num_epochs = 1\n",
        "  return config\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "5SoGnrnI41AY"
      },
      "cell_type": "code",
      "source": [
        "# Run model training and evaluation.\n",
        "state = train_and_evaluate(get_config())"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btBTadTkInY0"
      },
      "source": [
        "# Export the Model (new!)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "5zAHK-_zgPsq"
      },
      "outputs": [],
      "source": [
        "import frozendict\n",
        "from jax.experimental import mesh_utils\n",
        "\n",
        "# Create mesh to enable sharding in 2 dimensions\n",
        "ici_mesh = frozendict.frozendict({'data': 2, 'model': 2})\n",
        "devices = mesh_utils.create_device_mesh(tuple(ici_mesh.values()))\n",
        "mesh = jax.sharding.Mesh(devices, tuple(ici_mesh.keys()))\n",
        "mesh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nExX24wrf9GQ"
      },
      "source": [
        "## Shard the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "YWTtDrkJgKzk"
      },
      "outputs": [],
      "source": [
        "# Create the parameter sharding spec.\n",
        "import jax.sharding as jsharding\n",
        "\n",
        "def create_params_sharding_spec(mesh, p):\n",
        "  specs = (None,) * (len(p.shape) - 1) + ('model',) if len(p.shape) > 0 else ()\n",
        "  return jax.sharding.NamedSharding(\n",
        "      mesh, jsharding.PartitionSpec(*specs))\n",
        "\n",
        "params_sharding_spec = jax.tree_util.tree_map(\n",
        "    lambda p: create_params_sharding_spec(mesh, p), {'params':state.params})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "KNBSID8BdZeD"
      },
      "outputs": [],
      "source": [
        "params_sharding_spec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "rukWl7fsdW_7"
      },
      "outputs": [],
      "source": [
        "# Note here that the input tensor is sharded in two dimensions, which is not supported by DTensor.\n",
        "inputs_sharding_spec = jax.sharding.NamedSharding(\n",
        "    mesh, jsharding.PartitionSpec('data', 'model', None, None))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "a2DsB2oUhodg"
      },
      "outputs": [],
      "source": [
        "inputs_sharding_spec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "uGvHDWAlhg8f"
      },
      "outputs": [],
      "source": [
        "# Create a new instance of the model.\n",
        "model = Mnist()\n",
        "\n",
        "# Shard the model function.\n",
        "model_apply_fn = jax.jit(\n",
        "  model.apply,\n",
        "  in_shardings=(\n",
        "      params_sharding_spec,\n",
        "      inputs_sharding_spec,\n",
        "  ),\n",
        "  out_shardings=jax.sharding.NamedSharding(\n",
        "      mesh,\n",
        "      jsharding.PartitionSpec(None),\n",
        "  ),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "3p9BCzyzSl3g"
      },
      "outputs": [],
      "source": [
        "!rm -r /tmp/mnist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45vAasdVgCiZ"
      },
      "source": [
        "## Write the checkpoint to disk."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "4nYtY4psiZBu"
      },
      "outputs": [],
      "source": [
        "# Write the checkpoint.\n",
        "import orbax.checkpoint as ocp\n",
        "ckpter = ocp.Checkpointer(ocp.StandardCheckpointHandler())\n",
        "ckpter.save(\"/tmp/mnist/ckpt\", {'params': state.params})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "HsVzH-YCijU_"
      },
      "outputs": [],
      "source": [
        "!ls /tmp/mnist/ckpt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a5NhwdxgF6K"
      },
      "source": [
        "## Start using Orbax Export!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "OwqfZvFYjNFX"
      },
      "outputs": [],
      "source": [
        "from orbax.export import constants\n",
        "from orbax.export import jax_module\n",
        "from orbax.export import export_manager\n",
        "from orbax.export import serving_config as osc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "I91ifh4Lj4kW"
      },
      "outputs": [],
      "source": [
        "# Define the spec of the parameters.\n",
        "params_arg_spec = jax.tree_util.tree_map(\n",
        "    lambda p: jax.ShapeDtypeStruct(p.shape, p.dtype), {'params':state.params})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "zVAjOFHLkCvL"
      },
      "outputs": [],
      "source": [
        "# Create a JAX Module.\n",
        "model_function_name = 'mnist_forward_fn'\n",
        "\n",
        "orbax_module = jax_module.JaxModule(\n",
        "    params=params_arg_spec,\n",
        "    apply_fn={model_function_name: model_apply_fn},\n",
        "    export_version=constants.ExportModelType.ORBAX_MODEL, # Note this is a new version option.\n",
        "    jax2obm_kwargs={\n",
        "        constants.CHECKPOINT_PATH: os.fspath(\"ckpt\"),\n",
        "        },\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CF08FM_ggJFd"
      },
      "source": [
        "## Define pre- and post-processing functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "j3-6MXgLvA59"
      },
      "outputs": [],
      "source": [
        "# Define TF pre- and post-processing functions for serving.\n",
        "import tensorflow as tf\n",
        "\n",
        "# The data preprocessing function for resizing images\n",
        "def process_image(x: tf.Tensor) -> tf.Tensor:\n",
        "  # x is a uint8 tensor of shape (b, length, width, 3).\n",
        "  gray_image = tf.image.rgb_to_grayscale(x)\n",
        "  resized_image = tf.image.resize(gray_image, [28, 28]) / 255.0\n",
        "  return resized_image\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "rXMV2WWTeAu9"
      },
      "outputs": [],
      "source": [
        "# Define the spec of input arg (e.g., for the TF Preprocessing function).\n",
        "input_args_spec = [tf.TensorSpec((100, None, None, 3), tf.uint8)] # Set the batch size to 100.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "yinHnej4d4du"
      },
      "outputs": [],
      "source": [
        "# The post-processing function for selecting the most probable class.\n",
        "def select_digit(x: tf.Tensor) -> tf.Tensor:\n",
        "  return tf.math.argmax(x, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miUKEEqygRty"
      },
      "source": [
        "## Export the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Cbgl1RYOkwnH"
      },
      "outputs": [],
      "source": [
        "# Define the Orbax Export serving config.\n",
        "serving_config =osc.ServingConfig(\n",
        "    signature_key=model_function_name,\n",
        "    input_signature=input_args_spec,\n",
        "    tf_preprocessor=process_image,\n",
        "    tf_postprocessor=select_digit)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "qJYeo5BjjRRh"
      },
      "outputs": [],
      "source": [
        "# Create the Orbax Export Manager.\n",
        "em = export_manager.ExportManager(\n",
        "    module = orbax_module,\n",
        "    serving_configs = [serving_config])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "WGFeFwsNYhgq"
      },
      "outputs": [],
      "source": [
        "# Write model to disk.\n",
        "em.save(os.fspath(\"/tmp/mnist\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "3fb-iRLhQCnW"
      },
      "outputs": [],
      "source": [
        "!ls /tmp/mnist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfvOokjrgb-7"
      },
      "source": [
        "## Load the Model using Orbax Model Runner\n",
        "Note: the runner has a Python API but is in C++ under-the-hood."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "VdM6kXivVElL"
      },
      "outputs": [],
      "source": [
        "# Load the model using Orbax Model Runner (new!)\n",
        "from .neptune.python import orbax_model_runner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "RnARyDYRd7mz"
      },
      "outputs": [],
      "source": [
        "# Runner is in C++ with a Python API.\n",
        "runner = orbax_model_runner.ModelRunner(model_path=\"/tmp/mnist\")\n",
        "runner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "VnM0TlH0QDb3"
      },
      "outputs": [],
      "source": [
        "jax.devices()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "4dZMfd3yd9_e"
      },
      "outputs": [],
      "source": [
        "print(f\"Stable HLO will run on {runner.ifrt_platform_name()} platform with {runner.ifrt_device_count()} devices.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bxz9wkbpgpTv"
      },
      "source": [
        "## Run inference(Uncomment all the code below for interactive drawing and model prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "UZerRnrkVQcw"
      },
      "outputs": [],
      "source": [
        "# # Create prediction data.\n",
        "\n",
        "# from IPython.display import HTML, display\n",
        "# from google.colab.output import eval_js\n",
        "# from base64 import b64decode\n",
        "\n",
        "\n",
        "# canvas_html = \"\"\"\n",
        "# <canvas width=%d height=%d></canvas>\n",
        "# <button>Finish</button>\n",
        "# <script>\n",
        "# var canvas = document.querySelector('canvas')\n",
        "# var ctx = canvas.getContext('2d')\n",
        "# ctx.lineWidth = %d\n",
        "# ctx.strokeStyle = 'rgba(255,255,0,1)';\n",
        "# ctx.fillStyle = 'rgba(0,0,0,0.9)';\n",
        "# ctx.fillRect(0, 0, ctx.canvas.width, ctx.canvas.height)\n",
        "# var button = document.querySelector('button')\n",
        "# var mouse = {x: 0, y: 0}\n",
        "# canvas.addEventListener('mousemove', function(e) {\n",
        "#   mouse.x = e.pageX - this.offsetLeft\n",
        "#   mouse.y = e.pageY - this.offsetTop\n",
        "# })\n",
        "# canvas.onmousedown = ()=>{\n",
        "#   ctx.beginPath()\n",
        "#   ctx.moveTo(mouse.x, mouse.y)\n",
        "#   canvas.addEventListener('mousemove', onPaint)\n",
        "# }\n",
        "# canvas.onmouseup = ()=>{\n",
        "#   canvas.removeEventListener('mousemove', onPaint)\n",
        "# }\n",
        "# var onPaint = ()=>{\n",
        "#   ctx.lineTo(mouse.x, mouse.y)\n",
        "#   ctx.stroke()\n",
        "# }\n",
        "# var data = new Promise(resolve=>{\n",
        "#   button.onclick = ()=>{\n",
        "#     resolve(canvas.toDataURL('image/png'))\n",
        "#   }\n",
        "# })\n",
        "# </script>\n",
        "# \"\"\"\n",
        "\n",
        "# def draw(w=300, h=300, line_width=20):\n",
        "#   display(HTML(canvas_html % (w, h, line_width)))\n",
        "#   data = eval_js(\"data\")\n",
        "#   binary = b64decode(data.split(',')[1])\n",
        "#   return binary\n",
        "\n",
        "# image_data = draw()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "WhP6Sg1aZmyJ"
      },
      "outputs": [],
      "source": [
        "# image_data[:100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "gaXAH6vNZj5y"
      },
      "outputs": [],
      "source": [
        "# original_image = tf.image.decode_image(image_data, 3)\n",
        "# original_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "e1JuSZcMZp42"
      },
      "outputs": [],
      "source": [
        "# # Run the model\n",
        "# def create_model_inputs(image, batch_size):\n",
        "#   inputs = [np.asarray(image) for _ in range(batch_size)]\n",
        "#   batched_inputs = np.stack(inputs, axis=0)\n",
        "#   return batched_inputs\n",
        "\n",
        "# predicted_labels = runner.run(create_model_inputs(original_image, batch_size=100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "xeWH_RDLZ7HO"
      },
      "outputs": [],
      "source": [
        "# # Plot result!\n",
        "\n",
        "# from matplotlib import pyplot as plt\n",
        "# import numpy as np\n",
        "# from PIL import Image\n",
        "\n",
        "# def plot_image(image, title=\"\"):\n",
        "#   \"\"\"Plots images from image tensors.\n",
        "\n",
        "#   Args:\n",
        "#     image: 3D image tensor. [height, width, channels].\n",
        "#     title: Title to display in the plot.\n",
        "#   \"\"\"\n",
        "#   image = np.asarray(image)\n",
        "#   image = tf.clip_by_value(image, 0, 255)\n",
        "#   image = Image.fromarray(tf.cast(image, tf.uint8).numpy())\n",
        "#   plt.imshow(image)\n",
        "#   plt.axis(\"off\")\n",
        "#   plt.title(title)\n",
        "\n",
        "# plot_image(original_image, title=f\"predicted_label={predicted_labels[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "vtsN3Z_e3uul"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "last_runtime": {
        "build_target": "//learning/infra/mira/experimental/orbax_model/python:notebook_custom_kernel",
        "kind": "private"
      },
      "private_outputs": true,
      "provenance": [
        {
          "file_id": "154_a-jYJH5iJhzyxwxyMSJN4fx6qAZWV",
          "timestamp": 1743698843104
        },
        {
          "file_id": "10ZRKbwLbnzK-AFZ7qUqpybgpkwDA2V6U",
          "timestamp": 1743023760597
        }
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
