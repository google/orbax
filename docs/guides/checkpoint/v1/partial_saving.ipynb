{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVhdktQYovtC"
      },
      "source": [
        "# Partial Saving\n",
        "\n",
        "As deep learning models grow, often to hundreds of billions of parameters, managing their checkpoints becomes a significant challenge. Modifying a large checkpoint, even for a small change like adding metrics or a single layer, traditionally requires an inefficient \"load-modify-save\" cycle. This process uses lots memory and I/O bandwidth, as the entire multi-terabyte checkpoint must be loaded from storage, changed in memory, and written back out.\n",
        "\n",
        "Partial saving is designed to solve this problem by allowing you to modify a checkpoint without loading the entire object into host memory. It dramatically reduces peak memory usage, minimizes redundant I/O, and simplifies common model update workflows.\n",
        "\n",
        "### The Core Concept: The Partial Save Session\n",
        "\n",
        "Partial saving operates on a \"session\" or \"transaction\" model. Instead of overwriting your checkpoint directly, Orbax stages all changes in a temporary, in-progress location. The workflow consists of two stages:\n",
        "\n",
        "1. **Incremental Updates**: Calls to functions like `ocp.partial.save_pytree` contribute data to an in-progress checkpointing session. These changes are staged in a temporary location and are not yet visible at the final checkpoint path. From the user's perspective, the first save call simply begins this incremental process, and subsequent calls add to it.\n",
        "2. **Finalization**: A concluding call to `ocp.partial.finalize` completes the session. This action commits all the staged changes, making the checkpoint available at its final destination and ready for consumption.\n",
        "\n",
        "This approach ensures that the modification process is safe and atomic. If the process is interrupted before finalization, your original checkpoint remains untouched.\n",
        "\n",
        "\u003e **Note**: Partial saving currently does *NOT* support replacing data written out in previous save calls. If you have a need for Partial Saving Replacement (as opposed to the currently supported Partial Saving Addition), please reach out to the Orbax Checkpointing team so that development of this feature can be prioritized.\n",
        "\u003e\n",
        "\u003e The canonical way to do Replacement without partial saving is by loading the model, updating values in memory, then saving back out.\n",
        "\n",
        "### API and Basic Usage: Adding to a Checkpoint\n",
        "\n",
        "The partial saving API is available in the `orbax.checkpoint.v1.partial` module, but you'll likely access it via `ocp.partial`.\n",
        "\n",
        "The most common (and only supported) use case is adding new data (leaves or subtrees) to an existing PyTree checkpoint. The provided PyTree in a save call represents a set of updates. If a key does not exist in the on-disk checkpoint, it is treated as an addition. If a key already exists, it is viewed as a replacement (currently not allowed), and results in a `NotImplementedError`.\n",
        "\n",
        "### Code Example: A Simple Addition Workflow\n",
        "\n",
        "Let's start with an initial training state, then update that state with new data in a separate step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Tso7w8nOu0j9"
      },
      "outputs": [],
      "source": [
        "from orbax.checkpoint import v1 as ocp\n",
        "import numpy as np\n",
        "import jax\n",
        "from etils import epath"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnOVdpQfM7Q5"
      },
      "source": [
        "#### Initial Save\n",
        "\n",
        "Let's say we have an initial training state. The first call creates a temporary directory (e.g., `/tmp/partial_save/ckpt.partial_save`) and saves the initial state there."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "J8WNdB4fNIZ6"
      },
      "outputs": [],
      "source": [
        "path = epath.Path('/tmp/partial_save/ckpt')\n",
        "path.parent.rmtree(missing_ok=True)\n",
        "\n",
        "initial_state = {\n",
        "    'params': {\n",
        "        'layer0': np.arange(8),\n",
        "    },\n",
        "    'step': 10000,\n",
        "}\n",
        "\n",
        "ocp.partial.save_pytree(path, initial_state)\n",
        "assert not path.exists()\n",
        "assert (path.parent / (path.name + '.partial_save')).exists()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjEOIuLsNV3w"
      },
      "source": [
        "#### Add More Data\n",
        "\n",
        "After training some more, we have a new layer ready to be added. A subsequent call adds the new layer to the same temporary directory. Orbax merges the new PyTree with the existing one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3Ul5GzgSNTZE"
      },
      "outputs": [],
      "source": [
        "new_state = {\n",
        "    'params': {\n",
        "        'layer1': np.ones(4),\n",
        "    },\n",
        "}\n",
        "\n",
        "ocp.partial.save_pytree(path, new_state)\n",
        "assert not path.exists()\n",
        "assert (path.parent / (path.name + '.partial_save')).exists()"
      ]
    },
    {
      "metadata": {
        "id": "QOL0AbB1JPHJ"
      },
      "cell_type": "markdown",
      "source": [
        "#### Aside: Loading Before Finalizing\n",
        "\n",
        "Before finalizing the checkpoint, let's see what happens if we try to load the partial checkpoint."
      ]
    },
    {
      "metadata": {
        "id": "Pupu435wJbpD"
      },
      "cell_type": "code",
      "source": [
        "try:\n",
        "  ocp.load_pytree(path)\n",
        "except Exception as e:\n",
        "  print(\"LOAD ERROR\")\n",
        "  print(e)"
      ],
      "outputs": [],
      "execution_count": 4
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-0NSIIUNgsl"
      },
      "source": [
        "#### Finalize the Checkpoint\n",
        "\n",
        "This atomically renames the temporary directory to the final path, making it a complete, readable checkpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "NB22VdysNg6k"
      },
      "outputs": [],
      "source": [
        "ocp.partial.finalize(path)\n",
        "assert not (path.parent / (path.name + '.partial_save')).exists()\n",
        "assert path.exists()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zywxofENsJF"
      },
      "source": [
        "#### Verify the Result\n",
        "\n",
        "Now, we can load the checkpoint and see the merged result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7HZFdc2sNr7T"
      },
      "outputs": [],
      "source": [
        "restored_state = ocp.load_pytree(path)\n",
        "\n",
        "expected_state = {\n",
        "  'params': {\n",
        "    'layer0': np.array([0, 1, 2, 3, 4, 5, 6, 7]),\n",
        "    'layer1': np.array([1., 1., 1., 1.])\n",
        "  },\n",
        "  'step': 10000,\n",
        "}\n",
        "\n",
        "def is_equal(x, y):\n",
        "  if isinstance(x, np.ndarray):\n",
        "    assert np.allclose(x, y)\n",
        "  else:\n",
        "    assert x == y\n",
        "\n",
        "jax.tree.map(is_equal, restored_state, expected_state)\n",
        "restored_state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WATTNHQiu4X-"
      },
      "source": [
        "### API Reference\n",
        "\n",
        " - `ocp.partial.save_pytree()` / `ocp.partial.save_pytree_async()`: Saves a PyTree to the temporary partial save location. These functions can be called multiple times.\n",
        " - `ocp.partial.finalize()`: Commits the transaction, making the checkpoint permanent at the specified path. This must be called to complete the process.\n",
        "\n",
        "### Advanced Workflow: Combining Partial Saving and Partial Restore\n",
        "\n",
        "When combined with Partial Restore, this feature can enable highly efficient, targeted updates to massive checkpoints with a minimal memory footprint. You can use Partial Restore for a memory-efficient *read*, perform modifications, and then use Partial Save for a flexible and efficient *write*.\n",
        "\n",
        "#### Use Case: Creating an Inference-Ready Checkpoint\n",
        "\n",
        "Imagine you have a 2TB training checkpoint containing model params and a bulky optimizer_state. You want to create a smaller, inference-ready checkpoint that:\n",
        " - Contains only the `params`.\n",
        " - Has an updated `encoder_stack` within the params from a recent fine-tuning run.\n",
        "\n",
        "This entire process can be done without ever loading the massive optimizer_state into memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "NGhxpqrGvKK0"
      },
      "outputs": [],
      "source": [
        "from orbax.checkpoint import v1 as ocp\n",
        "import numpy as np\n",
        "import jax\n",
        "from etils import epath"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBCzE_SUuGES"
      },
      "source": [
        "#### Setup\n",
        "\n",
        "Create a large, multi-part \"base\" checkpoint to simulate a real scenario. This represents a very large model, but we only write it to disk. We never load it all at once (other than to view the metadata)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "RIQ0eUibuHOr"
      },
      "outputs": [],
      "source": [
        "base_path = epath.Path('/tmp/base_model/ckpt')\n",
        "base_path.rmtree(missing_ok=True)\n",
        "\n",
        "sharding = jax.sharding.NamedSharding(\n",
        "    jax.sharding.Mesh(jax.devices(), ('model',)),\n",
        "    jax.sharding.PartitionSpec(\n",
        "        'model',\n",
        "    ),\n",
        ")\n",
        "create_sharded_array = lambda x: jax.device_put(x, sharding)\n",
        "base_model_state = {\n",
        "    'params': {\n",
        "        'large_embedding_table': np.ones((1024, 1024)), # A large array\n",
        "        'encoder_stack': {f'layer_{i}': np.random.rand(2) for i in range(4)}, # The part we will replace\n",
        "        'classification_head': np.random.rand(8),\n",
        "    },\n",
        "    'optimizer_state': [np.random.rand(128) for _ in range(16)],\n",
        "}\n",
        "base_model_state = jax.tree.map(create_sharded_array, base_model_state)\n",
        "ocp.save_pytree(base_path, base_model_state)\n",
        "\n",
        "abstract_base_model_state = jax.tree.map(\n",
        "    ocp.arrays.to_shape_dtype_struct,\n",
        "    base_model_state\n",
        ")\n",
        "init_ckpt = ocp.load_pytree(base_path, abstract_base_model_state)\n",
        "print(\"\\n--- Setup ---\")\n",
        "print(f\"Optimizer state exists in initial checkpoint: {'optimizer_state' in init_ckpt}\")\n",
        "print(f\"Model version exists in initial checkpoint: {'model_version' in init_ckpt}\")\n",
        "for layer, weights in init_ckpt['params']['encoder_stack'].items():\n",
        "    print(f\"Original {layer}: {weights}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dkUhT-CuijA"
      },
      "source": [
        "#### The Efficient Update Workflow\n",
        "\n",
        "Use Partial Restore (Omission mode) to load ONLY the `params`. Create a reference PyTree that only has the `params` structure. This tells Orbax to ignore everything else (like `optimizer_state`). Enable partial loading via `Context` to allow omitting nodes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "UkMkMiP0uiDl"
      },
      "outputs": [],
      "source": [
        "inference_path = epath.Path('/tmp/inference_model/ckpt')\n",
        "inference_path.parent.rmtree(missing_ok=True)\n",
        "\n",
        "abstract_params = jax.tree.map(\n",
        "    ocp.arrays.to_shape_dtype_struct, {'params': base_model_state['params']}\n",
        ")\n",
        "\n",
        "with ocp.Context(\n",
        "    pytree_options=ocp.options.PyTreeOptions(\n",
        "        loading=ocp.options.PyTreeOptions.Loading(partial_load=True)\n",
        "    )\n",
        "):\n",
        "    loaded_params = ocp.load_pytree(base_path, abstract_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUT-1CxZ7vcg"
      },
      "source": [
        "At this point, `params` is in memory, but `optimizer_state` was never loaded.\n",
        "\n",
        "#### Update and Partial Save\n",
        "\n",
        "Modify the loaded parameters in memory. Add new metadata that might be useful for inference. Use Partial Save to write the modified `params` and new metadata to the new inference checkpoint location. Finalize the new, smaller, inference-ready checkpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "qKZeIYmL7uyu"
      },
      "outputs": [],
      "source": [
        "save_params = {}  # Used to create abstract params for inference\n",
        "\n",
        "metadata = {'model_version': 'v1.2-finetuned'}\n",
        "save_params = ocp.tree.merge(save_params, metadata)\n",
        "ocp.partial.save_pytree(inference_path, metadata)  # Initial partial save for metadata\n",
        "\n",
        "for layer, weights in loaded_params['params']['encoder_stack'].items():\n",
        "  new_weights = weights + np.random.rand(2)\n",
        "  stack_layer = {\n",
        "      'params': {\n",
        "          'encoder_stack': {\n",
        "              layer: jax.tree.map(\n",
        "                  create_sharded_array, new_weights\n",
        "              ),\n",
        "          }\n",
        "      },\n",
        "  }\n",
        "  save_params = ocp.tree.merge(save_params, stack_layer)\n",
        "  ocp.partial.save_pytree(inference_path, stack_layer)  # One partial save per layer\n",
        "\n",
        "ocp.partial.finalize(inference_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EO5X3mc58KMu"
      },
      "source": [
        "#### Verification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "msG8W-Xv8GtY"
      },
      "outputs": [],
      "source": [
        "abstract_params = jax.tree.map(\n",
        "    lambda x: (\n",
        "        str()\n",
        "        if isinstance(x, str)\n",
        "        else ocp.arrays.to_shape_dtype_struct(x)\n",
        "    ),\n",
        "    save_params\n",
        ")\n",
        "final_ckpt = ocp.load_pytree(inference_path, abstract_params)\n",
        "\n",
        "print(\"\\n--- Verification ---\")\n",
        "print(f\"Optimizer state exists in final checkpoint: {'optimizer_state' in final_ckpt}\")\n",
        "print(f\"Model version: {final_ckpt['model_version']}\")\n",
        "for layer, weights in final_ckpt['params']['encoder_stack'].items():\n",
        "    print(f\"New {layer}: {weights}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dP2Dx5wpvMpt"
      },
      "source": [
        "In this workflow, we created a new, pruned, and modified checkpoint. The key efficiency gain came from using Partial Restore to load only the params, completely avoiding the memory cost of the massive `optimizer_state`.\n",
        "\n",
        "### Atomicity Guarantees\n",
        "\n",
        "The use of a temporary directory and an atomic rename operation during finalization guarantees safety. If your program crashes mid-save, the original checkpoint (if any) is unharmed, and the temporary directory can be safely deleted."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
