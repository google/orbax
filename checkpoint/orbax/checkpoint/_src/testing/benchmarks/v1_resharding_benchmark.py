# Copyright 2026 The Orbax Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""Benchmarks for V1 free functions."""

from __future__ import annotations

import dataclasses
import pprint

from absl import logging
from etils import epath
import jax
from orbax.checkpoint import v1 as ocp
from orbax.checkpoint._src.testing.benchmarks import v1_benchmark
from orbax.checkpoint._src.testing.benchmarks.core import checkpoint_generation
from orbax.checkpoint._src.testing.benchmarks.core import core as benchmarks_core
from orbax.checkpoint._src.testing.benchmarks.core import metric as metric_lib


# ==============================================================================
# 1. Define the Options Dataclass for this specific benchmark
# ==============================================================================
@dataclasses.dataclass(frozen=True)
class V1ReshardingBenchmarkOptions(v1_benchmark.V1BenchmarkOptions):
  """Configuration options for benchmarks targeting V1ReshardingBenchmark.

  See parent class.

  Attributes:
    reference_checkpoint_path: The path to the reference checkpoint. This
      dictates the structure of the checkpoint to be restored.
    reference_sharding_path: The path to the reference sharding config. This
      dictates the shardings used for restoration.
  """

  reference_checkpoint_path: str | None = None
  reference_sharding_path: str | None = None

  def is_valid(self) -> bool:
    if self.reference_checkpoint_path is None:
      return False
    if self.reference_sharding_path is None:
      return False
    return super().is_valid()


# ==============================================================================
# 2. Implement the Benchmark Generator
# ==============================================================================
@benchmarks_core.benchmark_options(V1ReshardingBenchmarkOptions)
class V1ReshardingBenchmark(benchmarks_core.BenchmarksGenerator):
  """A concrete generator for resharding benchmarks."""

  def test_fn(
      self, context: benchmarks_core.TestContext
  ) -> benchmarks_core.TestResult:
    """The core test logic for a single save/restore cycle.

    This function is called for each combination of options generated by the
    framework. It uses the `context.options` to configure the handler
    dynamically for each run.

    Args:
      context: The test context containing the pytree, path, and options.

    Returns:
      The test result containing the metrics.
    """
    metrics = metric_lib.Metrics()
    assert context.pytree is None
    options = context.options
    assert isinstance(options, V1ReshardingBenchmarkOptions)

    logging.info("Benchmark options: %s", pprint.pformat(options))
    metrics_to_measure = v1_benchmark.get_metrics_to_measure(options)

    assert options.reference_checkpoint_path is not None
    assert options.reference_sharding_path is not None
    reference_checkpoint_path = epath.Path(
        options.reference_checkpoint_path
    )
    reference_sharding_path = epath.Path(
        options.reference_sharding_path
    )

    with ocp.Context(context=options.context):
      metadata = ocp.pytree_metadata(reference_checkpoint_path)
      abstract_pytree = (
          checkpoint_generation.get_abstract_state_from_sharding_config(
              reference_sharding_path,
              metadata.metadata,
              devices=context.mesh.devices,
          )
      )

      if options.enable_trace:
        jax.profiler.start_trace(context.path / "trace_load")
      with metrics.measure("load", metrics_to_measure):
        restored_pytree = ocp.load_pytree(
            reference_checkpoint_path, abstract_pytree
        )
      v1_benchmark.clear_pytree(restored_pytree)
      if options.enable_trace:
        jax.profiler.stop_trace()

    return benchmarks_core.TestResult(metrics=metrics)
