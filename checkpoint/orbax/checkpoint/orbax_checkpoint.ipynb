{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLDYvbGmkbUF"
      },
      "source": [
        "# Checkpointing with Orbax\n",
        "\n",
        "\u003ca href=\"http://colab.research.google.com/github/google/orbax/blob/main/orbax//checkpoint/orbax_checkpoint.ipynb\" \u003e\u003cimg src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/\u003e\u003c/a\u003e\n",
        "\n",
        "Take a look at https://github.com/google/orbax/blob/main/docs/checkpoint.md for additional documentation on Orbax checkpointing APIs.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sUD8KStVKEV"
      },
      "source": [
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UtRkioGNcBeH"
      },
      "outputs": [],
      "source": [
        "!pip install orbax\n",
        "!pip install nest_asyncio\n",
        "# Needed to enable asyncio in colab environment.\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJhi2HT6W9i3"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from collections import namedtuple\n",
        "import jax\n",
        "from jax.sharding import Mesh, PartitionSpec\n",
        "from jax.experimental.pjit import pjit\n",
        "import numpy as np\n",
        "import os\n",
        "import portpicker\n",
        "from etils import epath\n",
        "from flax import traverse_util\n",
        "import orbax.checkpoint as orbax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6BK58qYZ6fD"
      },
      "outputs": [],
      "source": [
        "jax.config.update('jax_array', True)\n",
        "port = portpicker.pick_unused_port()\n",
        "jax.distributed.initialize(f'localhost:{port}', num_processes=1, process_id=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j8Sfk7-bab2_"
      },
      "outputs": [],
      "source": [
        "devices = np.asarray(jax.devices())\n",
        "mesh = Mesh(devices, ('data',))\n",
        "axes = PartitionSpec('data',)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Y1tG-q2agTf"
      },
      "outputs": [],
      "source": [
        "directory = epath.Path('checkpoint_data')\n",
        "directory.mkdir(parents=True, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x9J2vLLy_Kjh"
      },
      "outputs": [],
      "source": [
        "print(directory)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ADSHBafjGnO"
      },
      "source": [
        "# A Basic Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "coa1aJ42-rfd"
      },
      "outputs": [],
      "source": [
        "basic_dir = directory / 'basic'\n",
        "basic_dir.mkdir()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "egh94fWsY8u3"
      },
      "outputs": [],
      "source": [
        "options = orbax.CheckpointManagerOptions(save_interval_steps=1, max_to_keep=3)\n",
        "mngr = orbax.CheckpointManager(\n",
        "    basic_dir, orbax.Checkpointer(orbax.PyTreeCheckpointHandler()), options)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6NhiTjsqvfY"
      },
      "source": [
        "The CheckpointManager is constructed with `Checkpointer` and `CheckpointHandler` objects. We will discuss these further below, but at a high level, the `Checkpointer` controls the *manner in which* the object is saved while the `CheckpointHandler` deals with type-specific logic and provides extra options for customization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZkkIUOpjMV0"
      },
      "source": [
        "First, we'll need to perform some setup to create a train state that mimics in a very basic form how a real model might look. We use jax.Array for this is example, but it is also possible to use scalars or numpy arrays, assuming they are *replicated* or *not sharded*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1L1LBgvhZihS"
      },
      "outputs": [],
      "source": [
        "def create_initial_state():\n",
        "  state = {\n",
        "      'layer_0': {\n",
        "          'bias': np.zeros(16),\n",
        "          'kernel': np.arange(16),\n",
        "      },\n",
        "      'layer_1': {\n",
        "          'bias': np.zeros(8),\n",
        "          'kernel': np.arange(8),\n",
        "      },\n",
        "  }\n",
        "\n",
        "  create_sharded_array = pjit(lambda x: x, in_axis_resources=None, out_axis_resources=axes)\n",
        "  with Mesh(mesh.devices, mesh.axis_names):\n",
        "    state = jax.tree_map(create_sharded_array, state)\n",
        "\n",
        "  state['step'] = 0\n",
        "  return state\n",
        "\n",
        "def state_shape(state):\n",
        "  return jax.eval_shape(lambda: state)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-DZFqWUjqnR"
      },
      "source": [
        "Here's our mock training step. At every step, we save a checkpoint. Since we specified `max_to_keep=3` in our options, we expect to only have the latest 3 checkpoints at the end of training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "81UiMOv-bj8j"
      },
      "outputs": [],
      "source": [
        "state = create_initial_state()\n",
        "\n",
        "def train(step, state):\n",
        "  # do some training, modify state\n",
        "  state['step'] = step\n",
        "\n",
        "  mngr.save(step, state)\n",
        "\n",
        "  return state\n",
        "\n",
        "for step in range(5):\n",
        "  state = train(step, state)\n",
        "\n",
        "print(f'Steps: {mngr.all_steps()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lo5GCEw79n6G"
      },
      "source": [
        "After saving, we can restore the latest step. Since this `CheckpointManager` is\n",
        "only managing a single item, the arguments provided to `restore` should just\n",
        "match the `state` (see the below cell). See 'Multi-Object Checkpointing' for\n",
        "further details on how these arguments are used when there are multiple items.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wjyAjN1Q9nS9"
      },
      "outputs": [],
      "source": [
        "dummy_state = state_shape(state)\n",
        "restore_args = jax.tree_util.tree_map(\n",
        "    lambda _:\n",
        "        orbax.ArrayRestoreArgs(\n",
        "            restore_type=jax.Array,\n",
        "            mesh=mesh, \n",
        "            mesh_axes=axes), \n",
        "    state)\n",
        "restore_args['step'] = orbax.RestoreArgs(restore_type=int)\n",
        "mngr.restore(mngr.latest_step(), items=dummy_state, \n",
        "             restore_kwargs={'restore_args': restore_args})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSz98oEUDmGW"
      },
      "source": [
        "We can achieve the same result by just using `Checkpointer`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QJ4wjl3yDlTD"
      },
      "outputs": [],
      "source": [
        "ckptr = orbax.PyTreeCheckpointer()\n",
        "# restore_args can also be constructed \"automatically\" from a target PyTree.\n",
        "restore_args = orbax.checkpoint_utils.restore_args_from_target(mesh, \n",
        "                    state, jax.tree_util.tree_map(lambda _: axes, state))\n",
        "print(restore_args)\n",
        "print()\n",
        "# CheckpointManager saved the checkpoint under /\u003cdirectory\u003e/\u003cstep\u003e/default.\n",
        "# 'default' is used as the subdirectory name when the CheckpointManager has a\n",
        "# single item. See below for information on how to use multiple items or how\n",
        "# to customize this name.\n",
        "ckpt_path = mngr.directory / str(mngr.latest_step()) / 'default'\n",
        "ckptr.restore(ckpt_path, item=dummy_state, restore_args=restore_args)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMm_0Wd1cWLx"
      },
      "source": [
        "# Tracking Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlGWeyGIcdjx"
      },
      "source": [
        "When saving checkpoints across many steps, we are often interested in keeping only the best *n* checkpoints based on some metric.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxeNxKJycq9H"
      },
      "outputs": [],
      "source": [
        "ckpt_metrics_dir = directory / 'ckpt_with_metrics'\n",
        "ckpt_metrics_dir.mkdir()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4JPDibaYc4xw"
      },
      "outputs": [],
      "source": [
        "options = orbax.CheckpointManagerOptions(\n",
        "    max_to_keep=3, best_fn=lambda metrics: metrics['loss'], best_mode='min')\n",
        "mngr = orbax.CheckpointManager(\n",
        "    ckpt_metrics_dir, orbax.AsyncCheckpointer(orbax.PyTreeCheckpointHandler()),\n",
        "    options)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_v0jzQadGPa"
      },
      "outputs": [],
      "source": [
        "def get_metrics(step):\n",
        "  return {'accuracy': 1.0, 'loss': step * 1.5}\n",
        "\n",
        "\n",
        "def train(step, state):\n",
        "  # do some training, modify state\n",
        "  metrics = get_metrics(step)\n",
        "  state['step'] = step\n",
        "  state_save_args = jax.tree_map(lambda _: orbax.SaveArgs(), state)\n",
        "  mngr.save(step, state, metrics=metrics)\n",
        "  return state\n",
        "\n",
        "\n",
        "state = create_initial_state()\n",
        "for step in range(5):\n",
        "  state = train(step, state)\n",
        "\n",
        "mngr.wait_until_finished()\n",
        "print(f'Steps: {mngr.all_steps()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZLh39KEfaFn"
      },
      "source": [
        "Now that we track metrics, we will only keep the best checkpoints saved, while deleting the rest. Since our loss is getting progressively worse, and best_mode='min', we will keep the first checkpoints, rather than the most recent ones. The metrics may be an arbitrary PyTree; it is up to you to define how it is interpreted."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8bTdGJ4j-sQ"
      },
      "source": [
        "# Multi-Object Checkpointing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LnkNt3ulCQm"
      },
      "source": [
        "In the following example, we will show how to checkpoint multiple different objects at once using CheckpointManager."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EwHq9nmM-1PT"
      },
      "outputs": [],
      "source": [
        "multi_dir = directory / 'multi'\n",
        "multi_dir.mkdir()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vMES1J-ni-WJ"
      },
      "outputs": [],
      "source": [
        "# Save every 3 steps.\n",
        "options = orbax.CheckpointManagerOptions(save_interval_steps=3)\n",
        "mngr = orbax.CheckpointManager(\n",
        "    multi_dir, {\n",
        "        'state': orbax.Checkpointer(orbax.PyTreeCheckpointHandler()),\n",
        "        'metadata': orbax.Checkpointer(orbax.JsonCheckpointHandler())\n",
        "    }, options)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8HBcMzCfuTU"
      },
      "source": [
        "We can save multiple objects simply by specifying a Checkpointer/CheckpointHandler combination for each of them. While Checkpointers can typically be used with any CheckpointHandler, you'll need to ensure that your object can be saved and restored by the given CheckpointHandler."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4Gv7L4olc_n"
      },
      "outputs": [],
      "source": [
        "NUM_STEPS = 5\n",
        "\n",
        "def train(step, state):\n",
        "  # do some training, modify state\n",
        "  state['step'] = step\n",
        "  metadata['timestamp'] = time.time()\n",
        "\n",
        "  # save with default arguments for all params except 'step', which uses flax\n",
        "  state_save_args = jax.tree_map(lambda _: orbax.SaveArgs(), state)\n",
        "  state_save_args['step'] = orbax.SaveArgs(aggregate=True)\n",
        "\n",
        "  # with `force` a save will be performed even if it would not ordinarily do so,\n",
        "  # based on the step number.\n",
        "  force = False\n",
        "  if step == NUM_STEPS - 1:\n",
        "    force = True\n",
        "  save_performed = mngr.save(\n",
        "      step,\n",
        "      items={\n",
        "          'state': state,\n",
        "          'metadata': metadata\n",
        "      },\n",
        "      # save_kwargs must be a dict with the same keys as items.\n",
        "      # not all keys in items have to be provided, in which case default kwargs\n",
        "      # are used each value must be a dict with keyword args passed to the\n",
        "      # underlying CheckpointHandler for that item (see CheckpointManager\n",
        "      # object construction)\n",
        "      save_kwargs={'state': {\n",
        "          'save_args': state_save_args\n",
        "      }}, \n",
        "      force=force)\n",
        "  print(f'Save performed: {save_performed}')\n",
        "\n",
        "  return state\n",
        "\n",
        "\n",
        "state = create_initial_state()\n",
        "metadata = {\n",
        "    'version': 1.1,\n",
        "    'exp_name': 'my_test_exp',\n",
        "    'timestamp': 0,\n",
        "}\n",
        "for step in range(NUM_STEPS):\n",
        "  state = train(step, state)\n",
        "\n",
        "print(f'Steps: {mngr.all_steps()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuRKldW3olfe"
      },
      "source": [
        "We also have extra arguments to customize saving for the `step` parameter within the train state. Because this is only an integer, using the default storage mechanism, [Tensorstore](https://google.github.io/tensorstore/) might be somewhat overkill. It would be more efficient to store it, along with any other similarly small parameters, into a single file using [flax.serialization](https://flax.readthedocs.io/en/latest/flax.serialization.html). The parameters passed here should match the optional arguments for the provided `CheckpointHandler`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4vhUSFK_5fj"
      },
      "source": [
        "Let's try restoring the latest step. In the `items` argument, make sure to provide a key for each of the items you want to restore. The values of this `items` dictionary are what gets provided to `CheckpointHandler.restore` as the argument of `item`. As a result, it may be `None` if the `CheckpointHandler`\n",
        "does not depend on the value of `item`.\n",
        "\n",
        "The `restore_kwargs` argument should be a dictionary with matching top-level keys, but keys can be omitted if no arguments are needed. The values of the\n",
        "`restore_kwargs` dictionary are provided as keyword args to the matching `CheckpointHandler.restore`. For example, if a `CheckpointHandler` subclass called `FooBarCheckpointHandler` takes kwargs `foo` and `bar` (in addition to standard args like `path` and `item`, the restore_kwargs for `CheckpointManager` would be: \n",
        "\n",
        "```\n",
        "restore_kwargs = {'foobar_item': {'foo': ???, 'bar': ???}}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BHmv1H4F_7b4"
      },
      "outputs": [],
      "source": [
        "mngr.restore(mngr.latest_step(), \n",
        "             # Safe to provide None for `items` values because they are not\n",
        "             # really needed in this case. `restore_args` is needed though.\n",
        "             items={'state': None, 'metadata': None}, \n",
        "             restore_kwargs={'state': {'restore_args': restore_args}})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4BgWudbChzC"
      },
      "source": [
        "If we skip providing 'metadata' in `items`, it will not be returned in the result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJdaARcsAj5j"
      },
      "outputs": [],
      "source": [
        "mngr.restore(mngr.latest_step(), \n",
        "             items={'state': None}, \n",
        "             restore_kwargs={'state': {'restore_args': restore_args}})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vv9JdrIMgXKH"
      },
      "source": [
        "# Asynchronous Checkpointing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4hSQdYhgeRb"
      },
      "source": [
        "You may be wondering what the point of Checkpointer is, and why it is separate from CheckpointHandler. The reason for this is that Checkpointer may have different subclasses, each of which handles certain common logic that we would not want to reimplement for every different CheckpointHandler.\n",
        "\n",
        "This logic may include ensuring save operation atomicity and managing a background thread for asynchronous saving."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54lTCWujhEOl"
      },
      "outputs": [],
      "source": [
        "async_dir = directory / 'async'\n",
        "async_dir.mkdir()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d5BWAer0hJk3"
      },
      "outputs": [],
      "source": [
        "mngr = orbax.CheckpointManager(\n",
        "    async_dir, {\n",
        "        'state': orbax.AsyncCheckpointer(orbax.PyTreeCheckpointHandler()),\n",
        "        'metadata': orbax.Checkpointer(orbax.JsonCheckpointHandler())\n",
        "    })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBvFnxA8hSqR"
      },
      "source": [
        "With the above configuration, our metadata will be saved synchronously, but our state will be saved in a background thread. After calling save, all files for the state may not have been written yet. In the meantime, we may continue training. \n",
        "\n",
        "However, we need to call wait_until_finished before ending our training program to block for any outstanding save operations. Calling save again will do this automatically - you cannot have multiple saves for multiple steps running concurrently."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7cDzRGnHh_uC"
      },
      "outputs": [],
      "source": [
        "def train(step, state):\n",
        "  # do some training, modify state\n",
        "  state['step'] = step\n",
        "  metadata['timestamp'] = time.time()\n",
        "\n",
        "  mngr.save(\n",
        "      step,\n",
        "      items={\n",
        "          'state': state,\n",
        "          'metadata': metadata\n",
        "      })\n",
        "\n",
        "  return state\n",
        "\n",
        "\n",
        "state = create_initial_state()\n",
        "metadata = {\n",
        "    'version': 1.1,\n",
        "    'exp_name': 'my_test_exp',\n",
        "    'timestamp': 0,\n",
        "}\n",
        "for step in range(NUM_STEPS):\n",
        "  state = train(step, state)\n",
        "\n",
        "mngr.wait_until_finished()\n",
        "print(f'Steps: {mngr.all_steps()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LhlleItrj-Z"
      },
      "source": [
        "# Checkpointer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haVQ6YJ1ro4B"
      },
      "source": [
        "`Checkpointer` allows you to save an object to a specified directory without providing any of the structure or extra features that `CheckpointManager` does."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AyQkbTDOrn_t"
      },
      "outputs": [],
      "source": [
        "state = create_initial_state()\n",
        "ckptr = orbax.Checkpointer(orbax.PyTreeCheckpointHandler())\n",
        "\n",
        "existing_checkpoint_dir = multi_dir / '0' / 'state'\n",
        "restore_args = jax.tree_map(lambda _: orbax.ArrayRestoreArgs(mesh=mesh, mesh_axes=axes), state)\n",
        "restore_args['step'] = orbax.RestoreArgs()\n",
        "restored = ckptr.restore(existing_checkpoint_dir, restore_args=restore_args)\n",
        "\n",
        "d = orbax.utils.to_state_dict(restored)\n",
        "for k, v in traverse_util.flatten_dict(d, keep_empty_nodes=True).items():\n",
        "  k_str = '/'.join(k)\n",
        "  print(f'{k_str}: {v}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-JTtxeNtO95"
      },
      "source": [
        "As shown in this example, this object may be useful for restoring a pre-exisiting checkpoint without requiring a `CheckpointManager`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-_hqQoTtrAK"
      },
      "source": [
        "# CheckpointHandler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dBp6ACStu1C"
      },
      "source": [
        "**Important: `CheckpointHandler` should not be used independently of `Checkpointer` or `CheckpointManager`.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n95GvJMWZa6S"
      },
      "source": [
        "As shown above, `PyTreeCheckpointHandler` provides support for most standard use-cases, where a `PyTree` consisting of jax.Array, scalars, or numpy arrays can be saved using a combination of Tensorstore and msgpack.\n",
        "\n",
        "However, we may also wish to provide custom support for a novel type or storage medium. Below is an example of how `CheckpointHandler` can be overridden to support a sharded file concept."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J6We8clipdNG"
      },
      "outputs": [],
      "source": [
        "from typing import Any, List, Mapping, Optional\n",
        "import asyncio\n",
        "from concurrent import futures\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bv09X-feOqxU"
      },
      "outputs": [],
      "source": [
        "executor = futures.ThreadPoolExecutor(max_workers=2)\n",
        "def ctime():\n",
        "  return datetime.datetime.now(\n",
        "      tz=datetime.timezone.utc\n",
        "  ).isoformat(sep=' ', timespec='milliseconds')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_sB6beCCNmG"
      },
      "outputs": [],
      "source": [
        "class ShardedFile:\n",
        "\n",
        "  def __init__(self):\n",
        "    self.devices = [d for d in jax.devices() if d.host_id == jax.process_index()]\n",
        "\n",
        "  def get_device_shard(self, device):\n",
        "    return f'Data associated with device: {device}... '\n",
        "\n",
        "  def get(self):\n",
        "    data = f'Process {jax.process_index()}: '\n",
        "    for d in self.devices:\n",
        "      data += self.get_device_shard(d)\n",
        "    return data\n",
        "\n",
        "class ShardedFileWriter:\n",
        "\n",
        "  async def copy(self):\n",
        "    await asyncio.sleep(1)\n",
        "    self.local_file = self.sharded_file.get()\n",
        "    print(f'{ctime()}: done copy')\n",
        "\n",
        "  def commit(self):\n",
        "    path = epath.Path(self.path) / str(jax.process_index())\n",
        "\n",
        "    def _write():\n",
        "      time.sleep(5)\n",
        "      path.write_text(self.local_file)\n",
        "      print(f'{ctime()}: done commit')\n",
        "\n",
        "    future = executor.submit(_write)\n",
        "    print(f'{ctime()}: started commit')\n",
        "    return future\n",
        "    \n",
        "  def __init__(self, path: str, sharded_file: ShardedFile):\n",
        "    self.path = path\n",
        "    self.sharded_file = sharded_file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8kUX5hHHl6eu"
      },
      "outputs": [],
      "source": [
        "class ShardedFileCheckpointHandler(orbax.async_checkpoint_handler.AsyncCheckpointHandler):\n",
        "\n",
        "  async def async_save(self, directory: epath.Path, item: ShardedFile) -\u003e List[futures.Future]:\n",
        "    \"\"\"Saves the given item.\n",
        "\n",
        "    Args:\n",
        "      directory: save location directory.\n",
        "      item: nested dictionary.\n",
        "    \"\"\"\n",
        "    fw = ShardedFileWriter(os.fspath(directory), item)\n",
        "    await fw.copy()\n",
        "    return [fw.commit()]\n",
        "\n",
        "  def save(self, directory: epath.Path, item: Any, *args, **kwargs):\n",
        "    async def async_save(*args, **kwargs):\n",
        "      commit_futures = await self.async_save(*args, **kwargs)\n",
        "      # Futures are already running, so sequential waiting is equivalent to\n",
        "      # concurrent waiting.\n",
        "      for future in commit_futures:\n",
        "        future.result()  # Block on result.\n",
        "    asyncio.run(async_save(directory, item, *args, **kwargs))\n",
        "    orbax.utils.sync_global_devices('ShardedFileCheckpointHandler:save')\n",
        "\n",
        "  def restore(self,\n",
        "              directory: epath.Path,\n",
        "              item: Optional[bytes] = None) -\u003e str:\n",
        "    del item\n",
        "    path = directory / str(jax.process_index())\n",
        "    return path.read_text()\n",
        "\n",
        "  def structure(self, directory: epath.Path) -\u003e int:\n",
        "    return len(list(directory.iterdir()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jTVu-X1wh91"
      },
      "outputs": [],
      "source": [
        "handler_dir = directory / 'sync_handler'\n",
        "async_handler_dir = directory / 'async_handler'\n",
        "\n",
        "file = ShardedFile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0R21iM7wcye"
      },
      "outputs": [],
      "source": [
        "checkpointer = orbax.Checkpointer(ShardedFileCheckpointHandler())\n",
        "checkpointer.save(handler_dir, file)\n",
        "print(f'{ctime()}: done save')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nXYsB8wp0FBO"
      },
      "outputs": [],
      "source": [
        "checkpointer = orbax.AsyncCheckpointer(ShardedFileCheckpointHandler())\n",
        "checkpointer.save(async_handler_dir, file)\n",
        "print(f'{ctime()}: processing save')\n",
        "# do something else\n",
        "checkpointer.wait_until_finished()\n",
        "print(f'{ctime()}: done save')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-Y9XJV5Ov4I"
      },
      "outputs": [],
      "source": [
        "executor.shutdown()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8Z19O3G6vCi"
      },
      "source": [
        "# TypeHandler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6i8Rqfn6xXn"
      },
      "source": [
        "`TypeHandler` as a concept exists in conjunction with `PyTreeCheckpointHandler` to provide additional customization options for advanced users with custom types they wish to save as part of a PyTree.\n",
        "\n",
        "By default, Orbax includes handler implementations for `jax.Array`, `np.ndarray`, scalars, strings, and others. These are simply the leaf types supported by `PyTreeCheckpointHandler`.\n",
        "\n",
        "By implementing a subclass of `TypeHandler` and registering a type using `register_type_handler`, we can add support for a novel type."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jvpgN69I6xfs"
      },
      "outputs": [],
      "source": [
        "class Foo():\n",
        "  # Realistically we would use a dataclass for this, but this is just for\n",
        "  # illustration purposes.\n",
        "  def __init__(self, a, b, c):\n",
        "    self.a = a\n",
        "    self.b = b\n",
        "    self.c = c\n",
        "\n",
        "  def __str__(self):\n",
        "    return f'{self.a};{self.b};{self.c}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dlhtm54F-wAP"
      },
      "outputs": [],
      "source": [
        "class FooHandler(orbax.type_handlers.TypeHandler):\n",
        "\n",
        "  async def serialize(\n",
        "      self,\n",
        "      value: Foo,\n",
        "      info: orbax.type_handlers.ParamInfo,\n",
        "      args: Optional[orbax.SaveArgs] = None) -\u003e List[orbax.future.Future]:\n",
        "    # A more sophisticated implementation would make this write asynchronous.\n",
        "    (info.path / 'data.txt').write_text(str(value))\n",
        "    return []\n",
        "\n",
        "  async def deserialize(\n",
        "      self,\n",
        "      info: orbax.type_handlers.ParamInfo,\n",
        "      args: Optional[orbax.RestoreArgs] = None) -\u003e Foo:\n",
        "    entries = (info.path / 'data.txt').read_text().split(';')\n",
        "    assert len(entries) == 3\n",
        "    return Foo(*entries)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCV2uKCEpa-Y"
      },
      "outputs": [],
      "source": [
        "type_handler_dir = directory / 'type_handler'\n",
        "orbax.type_handlers.register_type_handler(Foo, FooHandler(), override=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3dU4RnxApul0"
      },
      "outputs": [],
      "source": [
        "foo_tree = {\n",
        "    'one_foo': Foo(2, 4, 6),\n",
        "    'two_foo': Foo(1, 2, 3),\n",
        "}\n",
        "ckptr = orbax.Checkpointer(orbax.PyTreeCheckpointHandler())\n",
        "ckptr.save(type_handler_dir, foo_tree)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nmwcbo41kqv-"
      },
      "outputs": [],
      "source": [
        "restore_args = jax.tree_util.tree_map(lambda _: orbax.RestoreArgs(restore_type=Foo), foo_tree)\n",
        "restored = ckptr.restore(type_handler_dir, restore_args=restore_args)\n",
        "jax.tree_util.tree_map(str, restored)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkcDNjLPzBfZ"
      },
      "source": [
        "# Transformations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rRnvnVaag00"
      },
      "source": [
        "A key component of the Orbax checkpointing library is PyTree [transformations](https://github.com/google/orbax/tree/main/orbax/checkpoint/transform_utils.py). While this functionality is designed to be as flexible as possible, it can be used to support:\n",
        "\n",
        "\n",
        "*   Partial restoration of checkpoints where some keys can be dropped and replaced with randomly initialized values.\n",
        "*   Checkpoint version compatiblity where newer checkpoints may have different structures than old ones.\n",
        "*   Mappings over keys, including one-to-one, many-to-one, one-to-many, and many-to-many transformations.\n",
        "\n",
        "The transformations library is discussed in detail [here](https://github.com/google/orbax/blob/main/docs/checkpoint.md#transformations), so we will avoid discussing all possible features and will instead focus on concrete examples.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1Jv2o91dc0u"
      },
      "source": [
        "Let's start with a simple example first."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KqrFG69ZeYGj"
      },
      "outputs": [],
      "source": [
        "from orbax.checkpoint.transform_utils import Transform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCABTrNtdcUd"
      },
      "outputs": [],
      "source": [
        "original_tree = {\n",
        "  'a': 1,\n",
        "  'b': {\n",
        "    'c': 5,\n",
        "    'd': [0, 1, 2, 3]\n",
        "  },\n",
        "  'f': 2,\n",
        "}\n",
        "transformations = {\n",
        "  'a1': Transform(original_key='a'),  # rename\n",
        "  'b': {\n",
        "    # doubled original\n",
        "    'c': Transform(value_fn=lambda v: v * 2)\n",
        "    # drop b/d\n",
        "  },\n",
        "  # one to many mapping\n",
        "  'x': Transform(multi_value_fn=lambda kv: kv['b']['d'][0]),\n",
        "  'y': Transform(multi_value_fn=lambda kv: kv['b']['d'][1:]),\n",
        "  # many to one mapping\n",
        "  'z': Transform(multi_value_fn=lambda kv: kv['a'] * 2 + sum(kv['b']['d'])),\n",
        "}\n",
        "new_tree = {  # defines the structure of the result\n",
        "  'a1': ...,\n",
        "  'b': {\n",
        "    'c': ...,\n",
        "  },\n",
        "  'x': ...,\n",
        "  'y': ...,\n",
        "  'z': ...,\n",
        "  # 'f' defined in original_tree and new_tree, but not in transforms. Value\n",
        "  # carried over from original_tree.\n",
        "  'f': ...,\n",
        "  # This value matters since it is not present in original_tree or\n",
        "  # transformations, so the value here will simply be preserved in the result.\n",
        "  'g': 5,\n",
        "}\n",
        "\n",
        "orbax.apply_transformations(original_tree, transformations, new_tree)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDJmZ0vufHa_"
      },
      "source": [
        "An important rule of thumb to remember is that the output of `apply_transformations` will always match the structure of `new_tree`. This provides an easy way to know exactly what your result will look like after applying transformations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxoLRny1fcB3"
      },
      "source": [
        "Often, users have to deal with very large PyTrees and it would become very burdensome to specify transformations for large numbers of keys. Our library provides two solutions to this: regexes and implicit transformations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThSx8Xnkf0I7"
      },
      "source": [
        "Implicit transformations have been alluded to in our first example, but let's focus on them specifically.\n",
        "\n",
        "In the following example, transformations is an empty dictionary, so we rely exclusively on implicit transformations. Key/value pairs present in `new_tree` but not in `original_tree` simply remain in place in the result, while a key present in `original_tree` but not in `new_tree` will be dropped from the result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "13HSRjvqf5Ei"
      },
      "outputs": [],
      "source": [
        "original_tree = {\n",
        "  'a': 1,\n",
        "  'b': {\n",
        "    'c': 5,\n",
        "    'd': 6,\n",
        "    'e': 7,\n",
        "  },\n",
        "  'f': 2,\n",
        "}\n",
        "transformations = {}\n",
        "new_tree = {\n",
        "  'a': ...,\n",
        "  'b': {\n",
        "    'c': ...,\n",
        "  },\n",
        "  'f': ...,\n",
        "  'g': {\n",
        "      'h': 3,\n",
        "      'i': 4,\n",
        "  },\n",
        "}\n",
        "\n",
        "orbax.apply_transformations(original_tree, transformations, new_tree)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1eb2mN0hQJC"
      },
      "source": [
        "We can also change the `default_to_original` argument to customize the behavior when keys are unspecified in the `transformations` tree. Setting `default_to_original=False` means that unspecified keys will be taken from `new_tree`, **not** `original_tree`.\n",
        "\n",
        "This can be useful if we just want to take a few values from our original checkpoint, while using the rest from our new state."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UgPNbDSyg5tI"
      },
      "outputs": [],
      "source": [
        "original_tree = {\n",
        "  'a': 1,\n",
        "  'b': {\n",
        "    'c': 5,\n",
        "    'd': 6,\n",
        "    'e': 7,\n",
        "  },\n",
        "  'f': 2,\n",
        "}\n",
        "transformations = {'a': Transform(value_fn=lambda x: x*10)}\n",
        "new_tree = {\n",
        "  'a': 11,\n",
        "  'b': {\n",
        "    'c': 12,\n",
        "    'd': 13,\n",
        "    'e': 14,\n",
        "  },\n",
        "  'f': 15,\n",
        "}\n",
        "orbax.apply_transformations(original_tree, transformations, new_tree, default_to_original=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOmfK3y_ie-S"
      },
      "source": [
        "Returning to our other feature: support for regexes. Real model states often represent a conceptual parameter (a single layer, perhaps) with multiple actual key/value pairs. In this case, it can be useful to use a regex to refer to the parameter in question."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7QGF92Ji2y-"
      },
      "source": [
        "In the following example, we have one model (conceputally a pretrained checkpoint) with two layers, and another model (conceputally our in-memory model state) with four layers. We would like to insert the two layers of the checkpoint as the middle two layers of the new state, while leaving the bottom and top layers randomly initialized."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kGe_C7vMc6eu"
      },
      "outputs": [],
      "source": [
        "import flax.linen as nn\n",
        "from orbax.checkpoint import test_utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwIXnuLXcU1A"
      },
      "outputs": [],
      "source": [
        "from flax.training.train_state import TrainState\n",
        "import optax\n",
        "from jax import numpy as jnp\n",
        "\n",
        "def init_flax_model(model):\n",
        "  params = model.init(jax.random.PRNGKey(0), jnp.ones([8, 8]))\n",
        "  tx = optax.adamw(learning_rate=0.001)\n",
        "  state = TrainState.create(apply_fn=model.apply, params=params, tx=tx)\n",
        "  return jax.tree_util.tree_map(np.asarray, state)\n",
        "\n",  
        "class SmallModel(nn.Module):\n",
        "  @nn.compact\n",
        "  def __call__(self, x):\n",
        "    x = x.reshape((x.shape[0], -1))\n",
        "    x = nn.Dense(features=8)(x)\n",
        "    x = nn.sigmoid(x)\n",
        "    x = nn.Dense(features=8)(x)\n",
        "    return x\n",
        "\n",
        "old_state = init_flax_model(SmallModel())\n",
        "# multiply by 100 to represent \"training\"\n",
        "old_state = jax.tree_util.tree_map(lambda x: x * 100, old_state)\n",
        "\n",
        "class LargeModel(nn.Module):\n",
        "  @nn.compact\n",
        "  def __call__(self, x):\n",
        "    x = x.reshape((x.shape[0], -1))  # flatten\n",
        "    x = nn.Dense(features=8)(x)\n",
        "    x = nn.sigmoid(x)\n",
        "    x = nn.Dense(features=4)(x)\n",
        "    x = nn.sigmoid(x)\n",
        "    x = nn.Dense(features=4)(x)\n",
        "    x = nn.sigmoid(x)\n",
        "    x = nn.Dense(features=2)(x)\n",
        "    return x\n",
        "\n",
        "new_state = init_flax_model(LargeModel())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CYwRzCqRcaPw"
      },
      "outputs": [],
      "source": [
        "transformations = {\n",
        "    # NewModel layer_0 is a newly inserted layer, thus use_fallback=True.\n",
        "    # The \"fallback\" tree in this case is new_tree.\n",
        "    # Since the layer_0 has the same name in old and new, we need to provide\n",
        "    # an indication that the value of layer_0 should come from new_tree rather\n",
        "    # than original_tree.\n",
        "    r'(.*)Dense_0(.*)': Transform(use_fallback=True),\n",
        "    # OriginalModel layer 0 maps to NewModel layer 1\n",
        "    r'(.*)Dense_1(.*)': Transform(original_key=r'\\1Dense_0\\2'),\n",
        "    # OriginalModel layer 1 maps to NewModel layer 2\n",
        "    r'(.*)Dense_2(.*)': Transform(original_key=r'\\1Dense_1\\2')\n",
        "}  # Note: NewModel layer 3 is newly added.\n",
        "restored_state = orbax.apply_transformations(old_state, transformations, new_state)\n",
        "print(restored_state.params['params'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHB0TdI7mdUK"
      },
      "source": [
        "We can see in the result that layers 0 and 3 are still small, while layers 1 and 2 have large values, coming from the original checkpoint."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "last_runtime": {
        "build_target": "//learning/deepmind/public/tools/ml_python:ml_notebook",
        "kind": "private"
      },
      "name": "orbax.checkpoint.ipynb",
      "private_outputs": true,
      "provenance": [
        {
          "file_id": "1roGdihskKLd0rU50JLnkFkdzJGBdQKnJ",
          "timestamp": 1660339899756
        }
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
